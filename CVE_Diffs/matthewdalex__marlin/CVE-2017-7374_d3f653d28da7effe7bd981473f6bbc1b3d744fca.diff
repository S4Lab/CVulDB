matthewdalex__marlin
commit d3f653d28da7effe7bd981473f6bbc1b3d744fca
Author:     Eric Biggers <ebiggers@google.com>
AuthorDate: Wed Jun 14 11:50:43 2017 -0700
Commit:     Siqi Lin <siqilin@google.com>
CommitDate: Mon Aug 14 15:46:18 2017 -0700

    ext4, pfk, block: stop putting keyring key directly in bio
    
    Referencing the keyring key ('struct key') directly from struct bio, as
    was implemented for inline encryption support in the "marlin" kernel, is
    incorrect because userspace may revoke, invalidate, update, expire, etc.
    the key using the keyctl() system call, and this only requires acquiring
    the key semaphore which cannot be held throughout the whole bio.
    Notably, revoking the keyring key while I/O is in flight can cause a
    full system crash/hang, as reported in b/30225438 and b/35988361.
    
    While the Android O userspace will be using the safer keyctl_unlink()
    instead of keyctl_revoke(), it's still unacceptable for userspace to be
    able to cause these types of problems.  Furthermore, using
    ->ci_keyring_key conflicts with the upstream fix for CVE-2017-7374
    ("fscrypt: remove broken support for detecting keyring key revocation")
    which intentionally removed ->ci_keyring_key because it was being used
    in another incorrect way.
    
    Solve the problem by copying the master key's payload into
    ext4_crypt_info.ci_raw_key and pointing the bios to there instead.  This
    is safe because ext4_crypt_info will live as long as the inode, which in
    turn lives as long as any I/O for its contents.  Furthermore, although
    we will now be making many more copies of the master key, it's not truly
    less secure because the master key was already in kernel memory anyway.
    Finally, the "wahoo" kernel stores the key in ext4_crypt_info as well.
    
    Bug: 30225438
    Bug: 32669756
    Bug: 35988361
    Bug: 37866910
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Change-Id: Ic30d9e85eb3091de2a683333bd1cae47f61f2abf

diff --git a/block/blk-merge.c b/block/blk-merge.c
index 3ebddaf34e8..d4de63d1447 100644
--- a/block/blk-merge.c
+++ b/block/blk-merge.c
@@ -1,6 +1,7 @@
 /*
  * Functions related to segment and merge handling
  */
+#include <crypto/algapi.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/bio.h>
@@ -550,8 +551,9 @@ static bool crypto_not_mergeable(const struct bio *bio, const struct bio *nxt)
 	 * same, don't merge. */
 	return ((bio->bi_crypt_ctx.bc_key_size !=
 		 nxt->bi_crypt_ctx.bc_key_size) ||
-		(bio->bi_crypt_ctx.bc_keyring_key !=
-		 nxt->bi_crypt_ctx.bc_keyring_key));
+		crypto_memneq(bio->bi_crypt_ctx.bc_key,
+			      nxt->bi_crypt_ctx.bc_key,
+			      bio->bi_crypt_ctx.bc_key_size));
 }
 
 /*
diff --git a/fs/ext4/crypto_key.c b/fs/ext4/crypto_key.c
index 0a054f412bc..e89afd71164 100644
--- a/fs/ext4/crypto_key.c
+++ b/fs/ext4/crypto_key.c
@@ -91,6 +91,7 @@ void ext4_free_crypt_info(struct ext4_crypt_info *ci)
 	if (ci->ci_keyring_key)
 		key_put(ci->ci_keyring_key);
 	crypto_free_ablkcipher(ci->ci_ctfm);
+	memset(ci, 0, sizeof(*ci)); /* sanitizes ->ci_raw_key */
 	kmem_cache_free(ext4_crypt_info_cachep, ci);
 }
 
@@ -241,13 +242,21 @@ retry:
 		up_read(&keyring_key->sem);
 		goto out;
 	}
-	/* If we don't need to derive, we still want to do everything
-	 * up until now to validate the key. It's cleaner to fail now
-	 * than to fail in block I/O. */
 	if (for_fname ||
 	    crypt_info->ci_data_mode != EXT4_ENCRYPTION_MODE_PRIVATE) {
 		res = ext4_derive_key_aes(ctx.nonce, master_key->raw,
 					  crypt_info->ci_raw_key);
+	} else {
+		/*
+		 * Inline encryption: no key derivation required because IVs are
+		 * assigned based on physical sector number, not based on the
+		 * offset within the file.
+		 */
+		BUILD_BUG_ON(sizeof(crypt_info->ci_raw_key) !=
+			     sizeof(master_key->raw));
+		memcpy(crypt_info->ci_raw_key,
+		       master_key->raw, sizeof(crypt_info->ci_raw_key));
+		res = 0;
 	}
 	up_read(&keyring_key->sem);
 	if (res)
@@ -288,7 +297,6 @@ got_key:
 out:
 	if (res == -ENOKEY)
 		res = 0;
-	memset(crypt_info->ci_raw_key, 0, sizeof(crypt_info->ci_raw_key));
 	ext4_free_crypt_info(crypt_info);
 	return res;
 }
@@ -311,7 +319,7 @@ void ext4_set_bio_crypt_context(struct inode *inode, struct bio *bio)
 		bio->bi_crypt_ctx.bc_flags |= (BC_ENCRYPT_FL |
 					       BC_AES_256_XTS_FL);
 		bio->bi_crypt_ctx.bc_key_size = EXT4_AES_256_XTS_KEY_SIZE;
-		bio->bi_crypt_ctx.bc_keyring_key = ci->ci_keyring_key;
+		bio->bi_crypt_ctx.bc_key = ci->ci_raw_key;
 	} else
 		bio->bi_crypt_ctx.bc_flags &= ~BC_ENCRYPT_FL;
 }
diff --git a/include/linux/blk_types.h b/include/linux/blk_types.h
index 2084ece5267..df4d31614d1 100644
--- a/include/linux/blk_types.h
+++ b/include/linux/blk_types.h
@@ -20,12 +20,10 @@ typedef void (bio_destructor_t) (struct bio *);
 #define BC_ENCRYPT_FL		0x00000001
 #define BC_AES_256_XTS_FL	0x00000002
 
-#define BC_MAX_ENCRYPTION_KEY_SIZE	64
-
 struct bio_crypt_ctx {
-	unsigned int	bc_flags;
-	unsigned int	bc_key_size;
-	struct key	*bc_keyring_key;
+	unsigned int		bc_flags;
+	unsigned int		bc_key_size;
+	const unsigned char	*bc_key;
 };
 
 /*
diff --git a/include/linux/pfk.h b/include/linux/pfk.h
index 8a6e787ce6a..fa5b7eaae20 100644
--- a/include/linux/pfk.h
+++ b/include/linux/pfk.h
@@ -19,19 +19,8 @@ struct ice_crypto_setting;
 
 #ifdef CONFIG_PFK
 
-#define PFK_AES_256_XTS_KEY_SIZE 64
 #define PFK_MAX_KEY_SIZE 64
 
-/*
- * This is passed in from userspace into the kernel keyring
- * TODO(skaramov): This is a layering violation, solution tracked by b/30252720.
- */
-struct pfk_encryption_key {
-	__u32 mode;
-	char raw[PFK_MAX_KEY_SIZE];
-	__u32 size;
-} __attribute__((__packed__));
-
 bool pfk_is_ready(void);
 int pfk_load_key_start(const struct bio *bio,
 		struct ice_crypto_setting *ice_setting, bool *is_pfe, bool);
diff --git a/security/pfe/pfk.c b/security/pfe/pfk.c
index f939ef5605c..370cfd61a26 100644
--- a/security/pfe/pfk.c
+++ b/security/pfe/pfk.c
@@ -37,7 +37,6 @@
 #include <crypto/ice.h>
 
 #include <linux/pfk.h>
-#include <keys/user-type.h>
 
 #include "pfk_kc.h"
 #include "objsec.h"
@@ -124,58 +123,40 @@ inline bool pfk_is_ready(void)
 }
 EXPORT_SYMBOL(pfk_is_ready);
 
-/*
- * get_keys_from_bio() - Retrieve keys from BIO.
- * @bio:					Pointer to BIO to retrieve keys from.
- * @keyring_key:	Retrieved keyring key.
- * @key:					Retrieved raw key.
- * @salt:					Retrieved salt.
- *
- * The function takes keyring key semaphore, the expectation from the caller is
- * to release the semaphore once keyring_key operations are complete.
- *
- * Return: true if keys have been successfully retrieved, false otherwise.
- *
- */
-static int get_keys_from_bio(const struct bio *bio, struct key **keyring_key,
-		unsigned char const **key, unsigned char const **salt) {
-	int ret;
-	struct user_key_payload *ukp;
-	struct pfk_encryption_key *master_key;
-	struct key *keyring_key_tmp;
-	if (!(bio->bi_crypt_ctx.bc_flags & BC_AES_256_XTS_FL)) {
-		printk(KERN_WARNING "%s: Unsupported mode\n", __func__);
-		return -EINVAL;
-	}
-	if (bio->bi_crypt_ctx.bc_key_size !=
-	    (PFK_SUPPORTED_KEY_SIZE + PFK_SUPPORTED_SALT_SIZE)) {
-		printk(KERN_WARNING
-				"%s: Unsupported key size. Expected [%d], "
-				"got [%d]\n", __func__,
-				(PFK_SUPPORTED_KEY_SIZE + PFK_SUPPORTED_SALT_SIZE),
-				bio->bi_crypt_ctx.bc_key_size);
-		return -EINVAL;
+static int get_key_from_bio(const struct bio *bio, bool *is_pfe,
+			    const unsigned char **key_ret, size_t *key_size_ret,
+			    const unsigned char **salt_ret, size_t *salt_size_ret,
+			    enum ice_cryto_algo_mode *algo_mode_ret,
+			    enum ice_crpto_key_size *key_size_type_ret)
+{
+	const struct bio_crypt_ctx *ctx = &bio->bi_crypt_ctx;
+
+	if (!(ctx->bc_flags & BC_ENCRYPT_FL)) {
+		*is_pfe = false;
+		return -ENOTSUPP;
 	}
-	keyring_key_tmp = bio->bi_crypt_ctx.bc_keyring_key;
-	BUG_ON(!keyring_key_tmp);
-	do {
-		ret = down_read_trylock(&keyring_key_tmp->sem);
-	} while (!ret);
-	ukp = ((struct user_key_payload *)keyring_key_tmp->payload.data);
-	if (!ukp || ukp->datalen != sizeof(struct pfk_encryption_key)) {
-		up_read(&keyring_key_tmp->sem);
-		return -ENOKEY;
+
+	if (!(ctx->bc_flags & BC_AES_256_XTS_FL)) {
+		pr_err("pfk: unsupported encryption algorithm (bc_flags=0x%x)\n",
+		       ctx->bc_flags);
+		return -ENOTSUPP;
 	}
-	master_key = (struct pfk_encryption_key *)ukp->data;
-	if (!master_key || master_key->size != PFK_AES_256_XTS_KEY_SIZE) {
-		printk_once(KERN_WARNING "%s: key size incorrect: %d\n",
-				__func__, master_key->size);
-		up_read(&keyring_key_tmp->sem);
-		return -ENOKEY;
+
+	if (ctx->bc_key_size !=
+	    PFK_SUPPORTED_KEY_SIZE + PFK_SUPPORTED_SALT_SIZE) {
+		pr_err("pfk: unsupported key size: %u\n", ctx->bc_key_size);
+		return -ENOTSUPP;
 	}
-	*keyring_key = keyring_key_tmp;
-	*key = &master_key->raw[0];
-	*salt = &master_key->raw[PFK_SUPPORTED_KEY_SIZE];
+
+	*key_ret = &ctx->bc_key[0];
+	*key_size_ret = PFK_SUPPORTED_KEY_SIZE;
+	*salt_ret = &ctx->bc_key[PFK_SUPPORTED_KEY_SIZE];
+	*salt_size_ret = PFK_SUPPORTED_SALT_SIZE;
+
+	*algo_mode_ret = ICE_CRYPTO_ALGO_MODE_AES_XTS;
+
+	BUILD_BUG_ON(PFK_SUPPORTED_KEY_SIZE != 256 / 8);
+	*key_size_type_ret = ICE_CRYPTO_KEY_SIZE_256;
 	return 0;
 }
 
@@ -209,7 +190,6 @@ int pfk_load_key_start(const struct bio *bio,
 	enum ice_cryto_algo_mode algo_mode = 0;
 	enum ice_crpto_key_size key_size_type = 0;
 	u32 key_index = 0;
-	struct key *keyring_key = NULL;
 
 	if (!is_pfe) {
 		pr_err("is_pfe is NULL\n");
@@ -230,18 +210,11 @@ int pfk_load_key_start(const struct bio *bio,
 		return -EINVAL;
 	}
 
-	if (bio->bi_crypt_ctx.bc_flags & BC_ENCRYPT_FL) {
-		ret = get_keys_from_bio(bio, &keyring_key, &key, &salt);
-		if (ret)
-			return ret;
-		key_size = PFK_SUPPORTED_KEY_SIZE;
-		salt_size = PFK_SUPPORTED_SALT_SIZE;
-		algo_mode = ICE_CRYPTO_ALGO_MODE_AES_XTS;
-		key_size_type = ICE_CRYPTO_KEY_SIZE_256;
-	} else {
-		*is_pfe = false;
-		return -ENOTSUPP;
-	}
+	ret = get_key_from_bio(bio, is_pfe, &key, &key_size, &salt, &salt_size,
+			       &algo_mode, &key_size_type);
+	if (ret)
+		return ret;
+
 #if 0  /* debug */
 	printk(KERN_WARNING "%s: Loading key w/ key[0:1] == [%.2x%.2x] and "
 	       "salt[0:1] == [%.2x%.2x] into key_index [%d]\n", __func__,
@@ -249,9 +222,6 @@ int pfk_load_key_start(const struct bio *bio,
 #endif
 	ret = pfk_kc_load_key_start(key, key_size, salt, salt_size, &key_index,
 			async);
-	/* Release the semaphore taken by get_keys_from_bio */
-	if (keyring_key)
-		up_read(&keyring_key->sem);
 	if (ret) {
 		if (ret != -EBUSY && ret != -EAGAIN) {
 			pr_err("start: could not load key into pfk key cache, "
@@ -286,7 +256,8 @@ int pfk_load_key_end(const struct bio *bio, bool *is_pfe)
 	const unsigned char *salt = NULL;
 	size_t key_size = 0;
 	size_t salt_size = 0;
-	struct key *keyring_key = NULL;
+	enum ice_cryto_algo_mode algo_mode = 0;
+	enum ice_crpto_key_size key_size_type = 0;
 
 	if (!is_pfe) {
 		pr_err("is_pfe is NULL\n");
@@ -302,21 +273,12 @@ int pfk_load_key_end(const struct bio *bio, bool *is_pfe)
 	if (!pfk_is_ready())
 		return -ENODEV;
 
-	if (bio->bi_crypt_ctx.bc_flags & BC_ENCRYPT_FL) {
-		ret = get_keys_from_bio(bio, &keyring_key, &key, &salt);
-		if (ret)
-			return ret;
-		key_size = PFK_SUPPORTED_KEY_SIZE;
-		salt_size = PFK_SUPPORTED_SALT_SIZE;
-	} else {
-		*is_pfe = false;
-		return -ENOTSUPP;
-	}
+	ret = get_key_from_bio(bio, is_pfe, &key, &key_size, &salt, &salt_size,
+			       &algo_mode, &key_size_type);
+	if (ret)
+		return ret;
 
 	pfk_kc_load_key_end(key, key_size, salt, salt_size);
-	/* Release the semaphore taken by get_keys_from_bio */
-	if (keyring_key)
-		up_read(&keyring_key->sem);
 
 	return 0;
 }
