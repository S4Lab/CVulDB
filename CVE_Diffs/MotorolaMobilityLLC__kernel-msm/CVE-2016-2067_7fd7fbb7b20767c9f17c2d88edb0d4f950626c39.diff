MotorolaMobilityLLC__kernel-msm
commit 7fd7fbb7b20767c9f17c2d88edb0d4f950626c39
Author:     Tarun Karra <tkarra@codeaurora.org>
AuthorDate: Thu Mar 17 21:10:36 2016 -0700
Commit:     Zhao Xuewen <zhaoxuewen@huawei.com>
CommitDate: Wed Jul 6 10:26:39 2016 +0800

    msm: kgsl: verify user memory permissions before mapping to GPU driver
    
    For user memory of type KGSL_USER_MEM_TYPE_ADDR mapped to GPU driver
    verify permissions and map GPU permissions same as CPU permissions.
    If elevated permissions are requested return an error to prevent
    privilege escalation. Without this check user could map readonly
    memory into GPU driver as readwrite and gain elevated privilege.
    
    Write permissions check is currently inverted causing readonly
    user pages to be mapped as readwrite in GPU driver. Fix this
    check to map readonly pages as readonly.
    
    CVE:CVE-2016-2067 Bug:ANDROID-28305757
    
    CRs-Fixed: 988993
    Change-Id: I0e097d7e4e4c414c0849e33bcc61a26fb94291ad
    Signed-off-by: Tarun Karra <tkarra@codeaurora.org>

diff --git a/drivers/gpu/msm/kgsl.c b/drivers/gpu/msm/kgsl.c
index 370b2f2fb184..8cfc20b71ed7 100644
--- a/drivers/gpu/msm/kgsl.c
+++ b/drivers/gpu/msm/kgsl.c
@@ -2624,6 +2624,20 @@ static int kgsl_setup_phys_file(struct kgsl_mem_entry *entry,
 }
 #endif
 
+static int check_vma_flags(struct vm_area_struct *vma,
+		unsigned int flags)
+{
+	unsigned long flags_requested = (VM_READ | VM_WRITE);
+
+	if (flags & KGSL_MEMFLAGS_GPUREADONLY)
+		flags_requested &= ~VM_WRITE;
+
+	if ((vma->vm_flags & flags_requested) == flags_requested)
+		return 0;
+
+	return -EFAULT;
+}
+
 static int check_vma(struct vm_area_struct *vma, struct file *vmfile,
 		struct kgsl_memdesc *memdesc)
 {
@@ -2637,7 +2651,7 @@ static int check_vma(struct vm_area_struct *vma, struct file *vmfile,
 	if (vma->vm_start != memdesc->useraddr ||
 		(memdesc->useraddr + memdesc->size) != vma->vm_end)
 		return -EINVAL;
-	return 0;
+	return check_vma_flags(vma, memdesc->flags);
 }
 
 static int memdesc_sg_virt(struct kgsl_memdesc *memdesc, struct file *vmfile)
@@ -2646,7 +2660,7 @@ static int memdesc_sg_virt(struct kgsl_memdesc *memdesc, struct file *vmfile)
 	long npages = 0, i;
 	unsigned long sglen = memdesc->size / PAGE_SIZE;
 	struct page **pages = NULL;
-	int write = (memdesc->flags & KGSL_MEMFLAGS_GPUREADONLY) != 0;
+	int write = ((memdesc->flags & KGSL_MEMFLAGS_GPUREADONLY) ? 0 : 1);
 
 	if (sglen == 0 || sglen >= LONG_MAX)
 		return -EINVAL;
@@ -2716,6 +2730,7 @@ static int kgsl_setup_useraddr(struct kgsl_mem_entry *entry,
 	struct kgsl_map_user_mem *param = data;
 	struct dma_buf *dmabuf = NULL;
 	struct vm_area_struct *vma = NULL;
+	int ret;
 
 	if (param->offset != 0 || param->hostptr == 0
 		|| !KGSL_IS_PAGE_ALIGNED(param->hostptr)
@@ -2732,6 +2747,12 @@ static int kgsl_setup_useraddr(struct kgsl_mem_entry *entry,
 	if (vma && vma->vm_file) {
 		int fd;
 
+		ret = check_vma_flags(vma, entry->memdesc.flags);
+		if (ret) {
+			up_read(&current->mm->mmap_sem);
+			return ret;
+		}
+
 		/*
 		 * Check to see that this isn't our own memory that we have
 		 * already mapped
@@ -2750,7 +2771,7 @@ static int kgsl_setup_useraddr(struct kgsl_mem_entry *entry,
 	up_read(&current->mm->mmap_sem);
 
 	if (!IS_ERR_OR_NULL(dmabuf)) {
-		int ret = kgsl_setup_dma_buf(entry, pagetable, device, dmabuf);
+		ret = kgsl_setup_dma_buf(entry, pagetable, device, dmabuf);
 		if (ret)
 			dma_buf_put(dmabuf);
 		return ret;
