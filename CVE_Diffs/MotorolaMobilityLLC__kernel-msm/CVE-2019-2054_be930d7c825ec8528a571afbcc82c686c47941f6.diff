MotorolaMobilityLLC__kernel-msm
commit be930d7c825ec8528a571afbcc82c686c47941f6
Author:     Andy Lutomirski <luto@kernel.org>
AuthorDate: Tue Apr 9 14:21:50 2019 +0530
Commit:     PDO SCM Team <hudsoncm@motorola.com>
CommitDate: Sat May 18 21:44:21 2019 -0500

    BACKPORT: seccomp: Add a seccomp_data parameter secure_computing()
    
    Currently, if arch code wants to supply seccomp_data directly to
    seccomp (which is generally much faster than having seccomp do it
    using the syscall_get_xyz() API), it has to use the two-phase
    seccomp hooks. Add it to the easy hooks, too.
    
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Perry Lutomirski <luto@kernel.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    (cherry picked from commit 2f275de5d1ed7269913ef9b4c64a13952c0a38e8)
    
    Mot-CRs-fixed: (CR)
    CVE-Fixed: CVE-2019-2054
    Bug: 119769499
    
    Change-Id: I96876ecd8d1743c289ecef6d2deb65361d1f5baa
    [ghackmann@google.com: drop changes to parisc, tile, and um, which
     didn't implement seccomp support in this kernel version]
    Signed-off-by: Greg Hackmann <ghackmann@google.com>
    Signed-off-by: Jignesh Patel <jignesh@motorola.com>
    Reviewed-on: https://gerrit.mot.com/1334262
    SLTApproved: Slta Waiver
    SME-Granted: SME Approvals Granted
    Tested-by: Jira Key
    Reviewed-by: Shi-Yong Li <a22381@motorola.com>
    Reviewed-by: Ling Jin <lingjin@motorola.com>
    Submit-Approved: Jira Key

diff --git a/arch/arm/kernel/ptrace.c b/arch/arm/kernel/ptrace.c
index 4d9375814b53..1027d3b54541 100644
--- a/arch/arm/kernel/ptrace.c
+++ b/arch/arm/kernel/ptrace.c
@@ -934,7 +934,7 @@ asmlinkage int syscall_trace_enter(struct pt_regs *regs, int scno)
 
 	/* Do the secure computing check first; failures should be fast. */
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
-	if (secure_computing() == -1)
+	if (secure_computing(NULL) == -1)
 		return -1;
 #else
 	/* XXX: remove this once OABI gets fixed */
diff --git a/arch/arm64/kernel/ptrace.c b/arch/arm64/kernel/ptrace.c
index 163e2bc643ea..a2609d020aa0 100644
--- a/arch/arm64/kernel/ptrace.c
+++ b/arch/arm64/kernel/ptrace.c
@@ -1146,7 +1146,7 @@ static void tracehook_report_syscall(struct pt_regs *regs,
 asmlinkage int syscall_trace_enter(struct pt_regs *regs)
 {
 	/* Do the secure computing check first; failures should be fast. */
-	if (secure_computing() == -1)
+	if (secure_computing(NULL) == -1)
 		return -1;
 
 	if (test_thread_flag(TIF_SYSCALL_TRACE))
diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c
index c1bd750494c1..1d816214e8bd 100644
--- a/arch/mips/kernel/ptrace.c
+++ b/arch/mips/kernel/ptrace.c
@@ -899,7 +899,7 @@ asmlinkage long syscall_trace_enter(struct pt_regs *regs, long syscall)
 	long ret = 0;
 	user_exit();
 
-	if (secure_computing() == -1)
+	if (secure_computing(NULL) == -1)
 		return -1;
 
 	if (test_thread_flag(TIF_SYSCALL_TRACE) &&
diff --git a/arch/s390/kernel/ptrace.c b/arch/s390/kernel/ptrace.c
index 99a567b70d16..d5dca6c14288 100644
--- a/arch/s390/kernel/ptrace.c
+++ b/arch/s390/kernel/ptrace.c
@@ -809,7 +809,7 @@ asmlinkage long do_syscall_trace_enter(struct pt_regs *regs)
 	long ret = 0;
 
 	/* Do the secure computing check first. */
-	if (secure_computing()) {
+	if (secure_computing(NULL)) {
 		/* seccomp failures shouldn't expose any additional code. */
 		ret = -1;
 		goto out;
diff --git a/include/linux/seccomp.h b/include/linux/seccomp.h
index a19ddacdac30..7e77beb28fbf 100644
--- a/include/linux/seccomp.h
+++ b/include/linux/seccomp.h
@@ -28,11 +28,11 @@ struct seccomp {
 };
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
-extern int __secure_computing(void);
-static inline int secure_computing(void)
+extern int __secure_computing(const struct seccomp_data *sd);
+static inline int secure_computing(const struct seccomp_data *sd)
 {
 	if (unlikely(test_thread_flag(TIF_SECCOMP)))
-		return  __secure_computing();
+		return  __secure_computing(sd);
 	return 0;
 }
 
@@ -61,7 +61,7 @@ struct seccomp { };
 struct seccomp_filter { };
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
-static inline int secure_computing(void) { return 0; }
+static inline int secure_computing(struct seccomp_data *sd) { return 0; }
 #else
 static inline void secure_computing_strict(int this_syscall) { return; }
 #endif
diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 30c682adcdeb..d692dee1a16c 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -599,9 +599,9 @@ void secure_computing_strict(int this_syscall)
 		BUG();
 }
 #else
-int __secure_computing(void)
+int __secure_computing(const struct seccomp_data *sd)
 {
-	u32 phase1_result = seccomp_phase1(NULL);
+	u32 phase1_result = seccomp_phase1(sd);
 
 	if (likely(phase1_result == SECCOMP_PHASE1_OK))
 		return 0;
