MotorolaMobilityLLC__kernel-msm
commit 5ffc74bead315eb7fa2b5440856abc4981680bb3
Author:     Mark Rutland <mark.rutland@arm.com>
AuthorDate: Tue May 29 09:51:10 2018 +0530
Commit:     Amarendra Reddy <amarenr@motorola.com>
CommitDate: Thu Jun 7 20:20:07 2018 -0500

    arm64: prep stack walkers for THREAD_INFO_IN_TASK
    
    When CONFIG_THREAD_INFO_IN_TASK is selected, task stacks may be freed
    before a task is destroyed. To account for this, the stacks are
    refcounted, and when manipulating the stack of another task, it is
    necessary to get/put the stack to ensure it isn't freed and/or re-used
    while we do so.
    
    This patch reworks the arm64 stack walking code to account for this.
    When CONFIG_THREAD_INFO_IN_TASK is not selected these perform no
    refcounting, and this should only be a structural change that does not
    affect behaviour.
    
    Mot-CRs-fixed: (CR)
    CVE-fixed: CVE-2018-9384
    Bug: 74356909
    
    Change-Id: I7ccaa5d8771b09bb4e074180ae325a65b7191ba8
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Cc: AKASHI Takahiro <takahiro.akashi@linaro.org>
    Cc: Perry Lutomirski <luto@kernel.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Reviewed-on: https://gerrit.mot.com/1182396
    SLTApproved: Slta Waiver
    SME-Granted: SME Approvals Granted
    Tested-by: Jira Key
    Reviewed-by: Igor Kovalenko <igork@motorola.com>
    Submit-Approved: Jira Key

diff --git a/arch/arm64/kernel/process.c b/arch/arm64/kernel/process.c
index fc0a7aa2ca82..a0abb02d1b44 100644
--- a/arch/arm64/kernel/process.c
+++ b/arch/arm64/kernel/process.c
@@ -423,27 +423,35 @@ struct task_struct *__switch_to(struct task_struct *prev,
 unsigned long get_wchan(struct task_struct *p)
 {
 	struct stackframe frame;
-	unsigned long stack_page;
+	unsigned long stack_page, ret = 0;
 	int count = 0;
 	if (!p || p == current || p->state == TASK_RUNNING)
 		return 0;
 
+	stack_page = (unsigned long)try_get_task_stack(p);
+	if (!stack_page)
+		return 0;
+
 	frame.fp = thread_saved_fp(p);
 	frame.sp = thread_saved_sp(p);
 	frame.pc = thread_saved_pc(p);
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	frame.graph = p->curr_ret_stack;
 #endif
-	stack_page = (unsigned long)task_stack_page(p);
 	do {
 		if (frame.sp < stack_page ||
 		    frame.sp >= stack_page + THREAD_SIZE ||
 		    unwind_frame(p, &frame))
-			return 0;
-		if (!in_sched_functions(frame.pc))
-			return frame.pc;
+			goto out;
+		if (!in_sched_functions(frame.pc)) {
+			ret = frame.pc;
+			goto out;
+		}
 	} while (count ++ < 16);
-	return 0;
+
+out:
+	put_task_stack(p);
+	return ret;
 }
 
 unsigned long arch_align_stack(unsigned long sp)
diff --git a/arch/arm64/kernel/stacktrace.c b/arch/arm64/kernel/stacktrace.c
index dee5ad5bdf21..ea3e453fdd14 100644
--- a/arch/arm64/kernel/stacktrace.c
+++ b/arch/arm64/kernel/stacktrace.c
@@ -162,6 +162,9 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	struct stack_trace_data data;
 	struct stackframe frame;
 
+	if (!try_get_task_stack(tsk))
+		return;
+
 	data.trace = trace;
 	data.skip = trace->skip;
 
@@ -183,6 +186,8 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	walk_stackframe(tsk, &frame, save_trace, &data);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
+
+	put_task_stack(tsk);
 }
 EXPORT_SYMBOL(save_stack_trace_tsk);
 
diff --git a/arch/arm64/kernel/traps.c b/arch/arm64/kernel/traps.c
index 893011f0faa5..6701215b0501 100644
--- a/arch/arm64/kernel/traps.c
+++ b/arch/arm64/kernel/traps.c
@@ -155,6 +155,14 @@ static void dump_backtrace(struct pt_regs *regs, struct task_struct *tsk)
 	unsigned long irq_stack_ptr;
 	int skip;
 
+	pr_debug("%s(regs = %p tsk = %p)\n", __func__, regs, tsk);
+
+	if (!tsk)
+		tsk = current;
+
+	if (!try_get_task_stack(tsk))
+		return;
+
 	/*
 	 * Switching between stacks is valid when tracing current and in
 	 * non-preemptible context.
@@ -225,6 +233,8 @@ static void dump_backtrace(struct pt_regs *regs, struct task_struct *tsk)
 				 stack + sizeof(struct pt_regs), false);
 		}
 	}
+
+	put_task_stack(tsk);
 }
 
 void show_stack(struct task_struct *tsk, unsigned long *sp)
