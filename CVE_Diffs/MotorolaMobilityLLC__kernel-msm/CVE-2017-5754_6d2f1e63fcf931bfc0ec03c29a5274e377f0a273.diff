MotorolaMobilityLLC__kernel-msm
commit 6d2f1e63fcf931bfc0ec03c29a5274e377f0a273
Author:     Will Deacon <will.deacon@arm.com>
AuthorDate: Thu Aug 10 14:13:33 2017 +0100
Commit:     PDO SCM Team <hudsoncm@motorola.com>
CommitDate: Mon Jun 18 11:58:29 2018 -0500

    FROMLIST: arm64: mm: Invalidate both kernel and user ASIDs when performing TLBI
    
    Since an mm has both a kernel and a user ASID, we need to ensure that
    broadcast TLB maintenance targets both address spaces so that things
    like CoW continue to work with the uaccess primitives in the kernel.
    
    Mot-CRs-fixed: (CR)
    CVE-fixed: CVE-2017-5754
    Bug: 69856074
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Tested-by: Shanker Donthineni <shankerd@codeaurora.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    (cherry picked from git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux.git
     commit 9b0de864b5bc298ea53005ad812f3386f81aee9c)
    
    Change-Id: I2369f242a6461795349568cc68ae6324244e6709
    Signed-off-by: Greg Hackmann <ghackmann@google.com>
    Reviewed-on: https://gerrit.mot.com/1132554
    SLTApproved: Slta Waiver
    SME-Granted: SME Approvals Granted
    Tested-by: Jira Key
    Reviewed-by: Igor Kovalenko <igork@motorola.com>
    Submit-Approved: Jira Key

diff --git a/arch/arm64/include/asm/tlbflush.h b/arch/arm64/include/asm/tlbflush.h
index 2db3219a1348..4222edf2a350 100644
--- a/arch/arm64/include/asm/tlbflush.h
+++ b/arch/arm64/include/asm/tlbflush.h
@@ -23,6 +23,7 @@
 
 #include <linux/sched.h>
 #include <asm/cputype.h>
+#include <asm/mmu.h>
 
 /*
  * Raw TLBI operations.
@@ -42,6 +43,11 @@
 
 #define __tlbi(op, ...)		__TLBI_N(op, ##__VA_ARGS__, 1, 0)
 
+#define __tlbi_user(op, arg) do {						\
+	if (arm64_kernel_unmapped_at_el0())					\
+		__tlbi(op, (arg) | USER_ASID_FLAG);				\
+} while (0)
+
 /*
  *	TLB Management
  *	==============
@@ -109,6 +115,7 @@ static inline void flush_tlb_mm(struct mm_struct *mm)
 
 	dsb(ishst);
 	__tlbi(aside1is, asid);
+	__tlbi_user(aside1is, asid);
 	dsb(ish);
 #endif
 }
@@ -127,6 +134,7 @@ static inline void flush_tlb_page(struct vm_area_struct *vma,
 
 	dsb(ishst);
 	__tlbi(vale1is, addr);
+	__tlbi_user(vale1is, addr);
 	dsb(ish);
 #endif
 }
@@ -154,10 +162,13 @@ static inline void __flush_tlb_range(struct vm_area_struct *vma,
 
 	dsb(ishst);
 	for (addr = start; addr < end; addr += 1 << (PAGE_SHIFT - 12)) {
-		if (last_level)
+		if (last_level) {
 			__tlbi(vale1is, addr);
-		else
+			__tlbi_user(vale1is, addr);
+		} else {
 			__tlbi(vae1is, addr);
+			__tlbi_user(vae1is, addr);
+		}
 	}
 	dsb(ish);
 }
@@ -197,6 +208,7 @@ static inline void __flush_tlb_pgtable(struct mm_struct *mm,
 	unsigned long addr = uaddr >> 12 | (ASID(mm) << 48);
 
 	__tlbi(vae1is, addr);
+	__tlbi_user(vae1is, addr);
 	dsb(ish);
 }
 
