MotorolaMobilityLLC__kernel-msm
commit 5ecb896240c2d15f9537194510d96cc80e5f852f
Author:     Will Deacon <will.deacon@arm.com>
AuthorDate: Tue Nov 14 14:29:19 2017 +0000
Commit:     PDO SCM Team <hudsoncm@motorola.com>
CommitDate: Tue Mar 20 08:38:25 2018 -0500

    FROMLIST: arm64: erratum: Work around Falkor erratum #E1003 in trampoline code
    
    We rely on an atomic swizzling of TTBR1 when transitioning from the entry
    trampoline to the kernel proper on an exception. We can't rely on this
    atomicity in the face of Falkor erratum #E1003, so on affected cores we
    can issue a TLB invalidation to invalidate the walk cache prior to
    jumping into the kernel. There is still the possibility of a TLB conflict
    here due to conflicting walk cache entries prior to the invalidation, but
    this doesn't appear to be the case on these CPUs in practice.
    
    Mot-CRs-fixed: (CR)
    CVE-fixed: CVE-2017-5754
    Bug: 69856074
    
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Tested-by: Laura Abbott <labbott@redhat.com>
    Tested-by: Shanker Donthineni <shankerd@codeaurora.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    (cherry picked from git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux.git
     commit d1777e686ad10ba7c594304429c6045fb79255a1)
    
    Change-Id: Ia6c7ffd47745c179738250afa01cb8bf8594b235
    [ghackmann@google.com: replace runtime alternative_if with a
     compile-time check for Code Aurora's out-of-tree CONFIG_ARCH_MSM8996.
     Kryo needs this workaround too, and 4.4 doesn't have any of the
     upstream Falkor errata infrastructure needed to detect this at boot time.]
    Signed-off-by: Greg Hackmann <ghackmann@google.com>
    Reviewed-on: https://gerrit.mot.com/1132559
    SME-Granted: SME Approvals Granted
    SLTApproved: Slta Waiver
    Tested-by: Jira Key
    Reviewed-by: Igor Kovalenko <igork@motorola.com>
    Submit-Approved: Jira Key

diff --git a/arch/arm64/kernel/entry.S b/arch/arm64/kernel/entry.S
index 303802c62dec..035e07223ce2 100644
--- a/arch/arm64/kernel/entry.S
+++ b/arch/arm64/kernel/entry.S
@@ -897,6 +897,16 @@ __ni_sys_trace:
 	sub	\tmp, \tmp, #(SWAPPER_DIR_SIZE + RESERVED_TTBR0_SIZE)
 	bic	\tmp, \tmp, #USER_ASID_FLAG
 	msr	ttbr1_el1, \tmp
+#ifdef CONFIG_ARCH_MSM8996
+	/* ASID already in \tmp[63:48] */
+	movk	\tmp, #:abs_g2_nc:(TRAMP_VALIAS >> 12)
+	movk	\tmp, #:abs_g1_nc:(TRAMP_VALIAS >> 12)
+	/* 2MB boundary containing the vectors, so we nobble the walk cache */
+	movk	\tmp, #:abs_g0_nc:((TRAMP_VALIAS & ~(SZ_2M - 1)) >> 12)
+	isb
+	tlbi	vae1, \tmp
+	dsb	nsh
+#endif /* CONFIG_ARCH_MSM8996 */
 	.endm
 
 	.macro tramp_unmap_kernel, tmp
